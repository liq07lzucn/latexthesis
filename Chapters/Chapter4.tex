\chapter{Experimental Results}
\lhead{Chapter 4. \emph{Experimental Results}}

The \texttt{L-BFGS-B} implementation was tested on the high performance cluster machines at NYU. In order to run these tests it was necessary to create a series of PBS files\footnote{PBS stands for Portable Batch System. This is software that performs job scheduling. It is used by High Performance Computing at NYU (and many other High Performance Computing Centers) to allocate computational tasks. In order to run jobs at the high performance clusters, a series of PBS batch files need to be created.} using a PBS generator script. This script generator created PBS files which in turn run bash shell scripts\footnote{Bash is a command processor. Each Bash script that was created includes a series of computer commands, namely, execution of the original \texttt{L-BFGS-B} software and the new code \texttt{L-BFGS-B-NS}.}. Several of these shell scripts are available at the repository \citep{lbfgsbNS}. The main reason to run scripts this way is because it achieves parallelism, and because the system sends confirmation e-mails and statistics about the different stages of the processes giving a lot of control to the practitioner.

\section{Exit Messages}

The original \texttt{L-BFGS-B} optimizer displays different messages depending on the condition that triggered the exit. The following is a list of some of the most common exit messages in the original \texttt{L-BFGS-B} optimizer.

\begin{itemize}

\item ``ABNORMAL\_TERMINATION\_IN\_LNSRCH'' This message means that there was a problem and the program's exit was premature. It is typically found for non-smooth functions where the line search breaks down. But the message could also be symptomatic of other problems.

\item ``CONVERGENCE: NORM\_OF\_PROJECTED\_GRADIENT\_LT\_PGTOL": Means that convergence was achieved because the norm of the projected gradient is small enough. Notice that this convergence message does not apply to \texttt{L-BFGS-B-NS} because of particular requirements for non-smooth functions involving the convex hull of projected gradients as explained in section \ref{terminator}. Instead it is replaced by

\item ``CONVERGENCE: ZERO\_GRAD\_IN\_CONV\_HULL" This means that the termination condition discussed in section \ref{terminator} was satisfied\footnote{This does not mean that the resulting vector is exactly equal to zero $0$, but it is small enough to satisfy the termination condition.}.

\item ``CONVERGENCE: REL\_REDUCTION\_OF\_F\_LT\_FACTR*EPSMCH": This convergence condition is achieved whenever the relative reduction of the value of function $f$ is smaller than a predefined factor times the machine precision $\epsilon$. This exit message does not apply to our tests. It was disabled by setting the factor ``FACTR'' to zero, both in our runs of \texttt{L-BFGS-B-NS} and our tests using the original code \texttt{L-BFGS-B}.

\end{itemize}

The limit on the number of iterations was set to $10,000$.

\section{Modified Rosenbrock Function} \label{ros}

Consider a modified version of the Rosenbrock function problem \citep{rosenbrock}:

\begin{equation} \label{modifiedrosenbrock}
    f(x) = (x_1 - 1)^2 + \sum_{i = 2}^n |x_i - x_{i - 1}^2|^p
\end{equation}

We can study the properties of function $f$ based on the properties of the function $\phi(t_i)$, where $\phi(t_i) = |t_i|^p$ and $t_i = x_i - x_{i - 1}^2$. The properties of the function depend on the value of the $p$ parameter\footnote{The original Rosenbrock function had a value of $p = 2$ and the second term was multiplied by $100$.}. This function can be proven to be locally Lipschitz continuous whenever $p \geq 1$. However, its second derivative blows up at zero whenever $p < 2$. Note that although $\phi(t_i)$ is convex for $p \geq 1$, $f$ is not convex.

The properties of $\phi(t_i)$ can be separated into different cases. Whenever $p > 1$ the derivative can be represented as:
\begin{equation}\label{firstderiv}
  \frac{d}{dt} \phi(t) = \pm p |t|^{p-1}
\end{equation}
and therefore, the limit of the derivative exists and is equal to zero near $t = 0$: \[ \lim_{t \to 0} \frac{d}{dt}\phi(t) = 0 \] From this we conclude that $f$ has a smooth first derivative for $p > 1$.

However, if $p = 1$, $\phi(t) = |t|$, and the absolute value function is not differentiable at $t = 0$. Note that, $\phi(t)$ is Lipschitz continuous at $t = 0$.

The second derivative provides a bit more of information.

\begin{equation}\label{secondderiv}
  \frac{d^2}{dt^2} \phi(t) = \pm p(p-1) |t|^{p-2}
\end{equation}

If $p \geq 2$ the function is twice continuously differentiable. However if $p < 2$, the second derivative becomes $\frac{p(p-1)}{|t|^{q}}$, where $q = 2 - p > 0$, and this second derivative blows up as $|t| \to 0$. The special case $p = 1$ has second derivative equal to zero since $p(p-1) = 0$ except at $t = 0$ where it is undefined. For $p < 1$, $\phi$ is not Lipschitz continuous at $t = 0$

Having explained the characteristics of the function, the next thing that needs to be defined is the region to be tested. We chose the region to be defined by the ``box'' with boundaries

\begin{equation}
  \begin{aligned}
    x_i = 
    \begin{cases}
      [-100, 100] & \text{if } i \in \text{ even numbers} \\
      [10, 100] & \text{if } i \in \text{ odd numbers}
    \end{cases}
  \end{aligned}
\end{equation}

The initial point was chosen to be the midpoint of the box, plus a different small perturbation for each dimension, chosen so that the line search does not reach the boundary of several dimensions in one step:

\begin{equation}
  \begin{aligned}
    x_i = \frac{u_i + l_i}{2} - \left(1 - 2^{1 - i}\right)
  \end{aligned}
\end{equation}

The problem is twice continuously differentiable for values of $p \geq 2$, but as the values of $p$ approach $1$, the original \texttt{L-BFGS-B} optimizer \underline{should} start to have problems. We tested the original \texttt{L-BFGS-B} optimizer on the modified Rosenbrock function with $p$ varying between $2$ and $0.9$. 

For a value of $p = 2$, the original \texttt{L-BFGS-B} yields good results as seen in Table \ref{pequal2}.

\begin{center}
  \begin{table}
    \begin{center}
      \scriptsize
      \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
        \hline
m  &  n   & \multicolumn{4}{|c|}{\texttt{L-BFGS-B} results} & \multicolumn{4}{|c|}{\texttt{L-BFGS-B-NS} results} \\ \hline
         &  & Iter. & \#fg & f & NPG &  Iter.  & \#fg & f & NSVCHPG \\ \hline
        5 & 4 & 2 & 23 & 9305.93 & 0.00207341 & 10 & 16 & 9305.93 & 3.57E-005\\
        10 & 4 & 2 & 29 & 9305.93 & 0.0034576345 & 10 & 16 & 9305.93 & 6.07E-005\\
        20 & 4 & 2 & 30 & 9305.93 & 0.0011789284 & 10 & 16 & 9305.93 & 6.07E-005\\
        5 & 6 & 2 & 19 & 18531.14 & 0.0045643053 & 10 & 16 & 18531.14 & 4.92E-004\\
        10 & 6 & 2 & 19 & 18531.14 & 0.0098673465 & 10 & 16 & 18531.14 & 1.89E-004\\
        20 & 6 & 2 & 19 & 18531.14 & 0.0098672632 & 10 & 16 & 18531.14 & 1.89E-004\\
        5 & 8 & 2 & 21 & 27756.35 & 0.0046836051 & 13 & 19 & 27756.35 & 4.02E-004\\
        10 & 8 & 2 & 20 & 27756.35 & 0.0094596482 & 14 & 20 & 27756.35 & 2.38E-006\\
        20 & 8 & 2 & 20 & 27756.35 & 0.0094708831 & 14 & 20 & 27756.35 & 2.61E-006\\
        5 & 10 & 2 & 21 & 36981.56 & 0.0033234587 & 15 & 21 & 36981.56 & 3.92E-005\\
        10 & 10 & 2 & 21 & 36981.56 & 0.0081012695 & 15 & 21 & 36981.56 & 8.65E-005\\
        20 & 10 & 2 & 21 & 36981.56 & 0.0082688034 & 15 & 21 & 36981.56 & 1.42E-004\\
        5 & 20 & 2 & 20 & 83107.61 & 0.0027406376 & 16 & 21 & 83107.61 & 1.41E-005\\
        10 & 20 & 2 & 20 & 83107.61 & 0.0041252207 & 16 & 21 & 83107.61 & 3.36E-005\\
        20 & 20 & 2 & 20 & 83107.61 & 0.0041233412 & 16 & 21 & 83107.61 & 7.15E-005\\
        %5 & 50 & 2 & 20 & 221485.76 & 0.0033002394 & 10 & 17 & 221485.76 & 4.45E-005\\
        %10 & 50 & 2 & 20 & 221485.76 & 0.0042830873 & 10 & 17 & 221485.76 & 2.13E-005\\
        %20 & 50 & 2 & 20 & 221485.76 & 0.0043179814 & 10 & 17 & 221485.76 & 2.13E-005\\
        5 & 100 & 2 & 20 & 452116.01 & 0.0019111682 & 16 & 21 & 452116.01 & 1.45E-004\\
        10 & 100 & 2 & 20 & 452116.01 & 0.002587029 & 16 & 21 & 452116.01 & 3.29E-004\\
        20 & 100 & 2 & 20 & 452116.01 & 0.0025871555 & 16 & 21 & 452116.01 & 6.10E-004\\
        5 & 200 & 2 & 20 & 913376.52& 0.0023793373 & 17 & 22 & 913376.52 & 1.64E-004\\
        10 & 200 & 2 & 20 & 913376.52 & 0.0031088411 & 17 & 22 & 913376.52 & 3.51E-004\\
        20 & 200 & 2 & 20 & 913376.52 & 0.003108401 & 17 & 22 & 913376.52 & 6.81E-004\\
        5 & 1000 & 2 & 20 & 4603460.52 & 0.0035296465 & 18 & 24 & 4603460.52 & 4.04E-005\\
        10 & 1000 & 2 & 20 & 4603460.52 & 0.0045067318 & 17 & 22 & 4603460.52 & 3.24E-004\\
        20 & 1000 & 2 & 20 & 4603460.52 & 0.0045070181 & 18 & 30 & 4603460.52 & 1.18E-005\\
        \hline
      \end{tabular}
      \caption[Modified Rosenbrock with $p = 2$]{Satisfactory results for the original algorithm \texttt{L-BFGS-B} applied to the Modified Rosenbrock function with $p = 2$.  And results for \texttt{L-BFGS-B-NS}; NPG: Norm of projected Gradient with tolerance$10^{-6}$. NSVCHPG: Norm of Smallest Vector in Convex Hull of Projected Gradients with $\tau_d = 10^{-6}, \tau_x = 10^{-3}$}
      \label{pequal2}
      \end{center}
  \end{table}
\end{center}

\subsection{Performance of \texttt{L-BFGS-B} and  \texttt{L-BFGS-B} on Smooth and Non-smooth cases}

In order to compare the results of \texttt{L-BFGS-B} with the results of \texttt{L-BFGS-B-NS}, we changed the norm of the gradient in \texttt{L-BFGS-B} from the infinity to the euclidean norm, other than that \texttt{L-BFGS-B} is exactly the same version as the original. In order to keep magnitudes comparable, the tolerance of the euclidean norm of the projected gradient in \texttt{L-BFGS-B} and the limit of the $NSVCHPG$ $\tau_d$ from \texttt{L-BFGS-B-NS} were both set to $10^{-6}$.

The values of $m$ (the memory of \texttt{L-BFGS}) that were tested are $5$, $10$ and $20$. The number of dimensions in this exercise ranges from $6$ to $1000$. The column $\#fg$ stands for the number of function and gradient evaluations taken, $f$ stands for the optimal value that was achieved by the optimization. $NPG$ shows the norm of the projected gradient, the termination tolerance for the euclidean norm of the projected gradients was $10^{-6}$. In all cases this test was satisfied. 

In table \ref{pequal2} $NSVCHPG$ is the norm of the smallest vector in the convex hull of projected gradients. You can see that since this function is smooth when $p = 2$, \texttt{L-BFGS-B} has no problems solving the test and that \texttt{L-BFGS-B-NS} reaches exactly the same values.

The overall conclusion from this exercise is that the original \texttt{L-BFGS-B} optimizer works well for the smooth modified Rosenbrock case and that \texttt{L-BFGS-B-NS} has a performance that can achieve a minimum that is just as good.


\begin{table}
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
      \hline
      m  &  n  &  p  & \multicolumn{3}{|c|}{\texttt{L-BFGS-B} results} & \multicolumn{3}{|c|}{\texttt{L-BFGS-B-NS} results} \\ \hline
      &&  & \#fg & f & NPG & \#fg & f & NSVCHPG \\ \hline
      %5 & 4 & 1 & 68 & 274.68 & 96.84 & 10749268 & 185.80 & NA\\
      10 & 4 & 1 & 68 & 274.68 & 96.84 & 93 & 177.00 & 4.77E-09 \\
      20 & 4 & 1 & 68 & 274.68 & 96.84 & 93 & 177.00 & 4.77E-09 \\
      %5 & 6 & 1 & 57 & 371.80 & 96.81 & 10738583 & 274.68 & NA\\
      10 & 6 & 1 & 57 & 371.80 & 96.81 & 113 & 274.68 & 6.54E-08 \\
      20 & 6 & 1 & 57 & 371.80 & 96.81 & 113 & 274.68 & 6.54E-08 \\
      %5 & 8 & 1 & 59 & 468.38 & 96.84 & 120 & 371.51 & 1.10E-08\\
      10 & 8 & 1 & 59 & 468.38 & 96.84 & 106 & 371.52 & 2.42E-09 \\
      20 & 8 & 1 & 59 & 468.38 & 96.84 & 106 & 371.52 & 2.42E-09 \\
      %5 & 10 & 1 & 59 & 565.28 & 96.83 & 274756 & 522.00 & NA\\
      10 & 10 & 1 & 59 & 565.28 & 96.83 & 188 & 521.64 & 1.98E-08 \\
      20 & 10 & 1 & 59 & 565.28 & 96.83 & 188 & 521.64 & 1.98E-08 \\
      %5 & 20 & 1 & 69 & 1,049.37 & 96.84 & 166 & 952.54 & 7.89E-03\\
      10 & 20 & 1 & 69 & 1,049.37 & 96.84 & 188 & 952.54 & 1.89E-08 \\
      20 & 20 & 1 & 69 & 1,049.37 & 96.84 & 279 & 952.54 & 7.90E-08 \\
      %5 & 50 & 1 & 55 & 2,502.10 & 96.84 & 240 & 2,405.11 & 1.75E-08\\
      %10 & 50 & 1 & 55 & 2,502.10 & 96.84 & 552 & 2,405.11 & 9.37E-03\\
      %20 & 50 & 1 & 55 & 2,502.10 & 96.84 & 206 & 2,405.11 & 6.78E-03\\
      %5 & 100 & 1 & 55 & 4,923.83 & 96.83 & 141 & 4,826.05 & 5.56E-08\\
      10 & 100 & 1 & 55 & 4,923.83 & 96.83 & 138 & 4,826.05 & 5.56E-08 \\
      20 & 100 & 1 & 55 & 4,923.83 & 96.83 & 138 & 4,826.05 & 5.56E-08 \\
      %5 & 200 & 1 & 55 & 9,767.31 & 96.83 & 139 & 9,667.93 & 7.72E-08\\
      10 & 200 & 1 & 55 & 9,767.31 & 96.83 & 140 & 9,667.93 & 7.72E-08 \\
      20 & 200 & 1 & 55 & 9,767.31 & 96.83 & 112 & 9,667.93 & 5.18E-08 \\
      %5 & 1000 & 1 & 55 & 48,515.21 & 96.83 & 193 & 48,403.14 & 5.72E-09\\
      10 & 1000 & 1 & 55 & 48,515.21 & 96.83 & 163 & 48,403.02 & 1.70E-07 \\
      20 & 1000 & 1 & 55 & 48,515.21 & 96.83 & 177 & 48,403.02 & 1.80E-07 \\
      \hline
    \end{tabular}
    \caption[Modified Rosenbrock with $p = 1$]{Unsatisfactory results for the original algorithm \texttt{L-BFGS-B} applied to the Modified Rosenbrock function with $p = 1$. And converging results for \texttt{L-BFGS-B-NS}; NPG: Norm of projected Gradient withtolerance = $10^{-6}$. NSVCHPG: Norm of Smallest Vector in Convex Hull of Projected Gradients with $\tau_d = 10^{-6}, \tau_x = 10^{-3}$}
  \label{pequal1merged}
  \end{center}
\end{table}

On the other hand, the value of $p = 1$ leads to an abnormal line search termination for \texttt{L-BFGS-B} in all of the cases presented. This is to be expected as the function is non-smooth. See table \ref{pequal1merged} where the norm of the resulting projected gradient never approaches zero. In this exercise, the memory length $m$ of \texttt{L-BFGS}, does not have an impact on the final value $f$ of the optimization, but this is because all cases crashed before the $5^{th}$ iteration and therefore all different cases of $m$ end up looking exactly the same.

\subsection{Performance of \texttt{L-BFGS-B-NS}}

Several other values of $p$ were also tested, among others $1.1$, $1.01$, $1.001$, ... , $1.00001$, $1$. With a tolerance of $10^{-6}$ \texttt{L-BFGS-B} always crashes as expected, those values where $p$ is closer to $1$ are the most difficult for the original algorithm to handle.  Values generated via \texttt{L-BFGS-B-NS} are comparatively better whenever $p < 2$, since the function is ``less'' smooth. Some runs of \texttt{L-BFGS-B-NS} fail to converge using the termination condition from section \ref{terminator}.

In table \ref{pmtable}, the parameter $p$ is varied and all other parameters are held constant.

\begin{table}
  \begin{center}
    \begin{tabular}{|l|l|l|p{1.6cm}|p{6cm}|}
      \hline
      p & Iterations & Value of f & Norm Smallest Vector in Convex Hull\\ \hline
      2 & 8 & 41,116,905.61 & 1.88E-03\\
      1.1 & 24 & 764,853.32 & 1.72E-06\\ 
      1.0001 & 27 & 484,394.49 & 1.91E-08 \\ 
      1.00001 & 84 & 484,195.01 & 1.06E-06 \\ 
      1.0000001 & 21 & 484,173.43 & 1.77E-08 \\ \hline
    \end{tabular}
    \caption[Number of algorithm Iterations Changing $p$]{This is the number of algorithm iterations for different values of $p$. The value of the projected gradient is presented as well. This exercise was run with $n = 10,000$, $m = 10$ and $\tau_d = \tau_x = 10^{-3}$}
    \label{pmtable}
  \end{center}
\end{table}

And finally a test run for values $p < 1$. In particular here a test of $p = 0.9$ on Table \ref{p09}. This test fails because of Lipschitz discontinuity of the function in the region.

\begin{table}
  \begin{center}
    \footnotesize
    \begin{tabular}{|l|l|l|l|l|l|l|l|}
      \hline
m  &  n  &  p  & \multicolumn{3}{|c|}{\texttt{L-BFGS-B} results} & \multicolumn{2}{|c|}{\texttt{L-BFGS-B-NS} results} \\ \hline
& &  & \#fg & f & NFG & \#fg & f \\ \hline
      5 & 2 & 0.9 & 21 & 142.3895656804 & 97 & 50358 & 81 \\ 
      10 & 2 & 0.9 & 21 & 142.3895656804 & 97 & 50358 & 81 \\
      20 & 2 & 0.9 & 21 & 142.3895656804 & 97 & 50358 & 81\\
      5 & 4 & 0.9 & 57 & 203.6867061962 & 96.8244771931 & 20010 & 203.6717690175\\
      10 & 4 & 0.9 & 57 & 203.6867061962 & 96.8244771931 & 20007 & 201.3635208544\\
      20 & 4 & 0.9 & 57 & 203.6867061962 & 96.8244771931 & 20007 & 201.3635208544\\
      5 & 6 & 0.9 & 90 & 264.8904504715 & 96.8377187807 & 20012 & 264.9727640136\\
      10 & 6 & 0.9 & 90 & 264.8904504715 & 96.8377187807 & 20006 & 263.4634677358\\
      20 & 6 & 0.9 & 90 & 264.8904504715 & 96.8377187807 & 20006 & 263.2710714257\\
      5 & 8 & 0.9 & 65 & 326.2465886362 & 96.8354703277 & 588470 & 326.2699902292\\
      10 & 8 & 0.9 & 65 & 326.2465886362 & 96.8354703277 & 20003 & 324.2733728009\\
      20 & 8 & 0.9 & 65 & 326.2465886362 & 96.8354703277 &  & \\
      5 & 10 & 0.9 & 55 & 387.6474214791 & 96.8328164056 & 588173 & 387.5671220185\\
      10 & 10 & 0.9 & 55 & 387.6474214791 & 96.8328164056 & 19998 & 386.9547954789\\
      20 & 10 & 0.9 & 55 & 387.6474214791 & 96.8328164056 & 20002 & 386.5111464469\\
      5 & 20 & 0.9 & 55 & 695.4247337795 & 96.8148669898 & 588234 & 694.0527666868\\
      10 & 20 & 0.9 & 55 & 695.4247337795 & 96.8148669898 & 20005 & 694.0391973604\\
      20 & 20 & 0.9 & 55 & 695.4247337795 & 96.8148669898 & 20003 & 682.9908544633\\
      5 & 50 & 0.9 & 53 & 1631.27559033 & 96.7138084598 & 588409 & 1613.5096637579\\
      10 & 50 & 0.9 & 53 & 1631.27559033 & 96.7138084598 & 20006 & 1613.5043396518\\
      20 & 50 & 0.9 & 53 & 1631.27559033 & 96.7138084598 & 20002 & 1604.0578060639\\
      5 & 100 & 0.9 & 53 & 3183.6955082727 & 96.7088482124 & 588409 & 3145.9378051899\\
      10 & 100 & 0.9 & 53 & 3183.6955082727 & 96.7088482124 & 20005 & 3145.9332306031\\
      20 & 100 & 0.9 & 53 & 3183.6955082727 & 96.7088482124 & 20007 & 3144.6121183855\\
      5 & 200 & 0.9 & 53 & 6288.5762389464 & 96.7063705729 & 588409 & 6210.7940850592\\
      10 & 200 & 0.9 & 53 & 6288.5762389464 & 96.7063705729 & 20010 & 6210.7940838524\\
      20 & 200 & 0.9 & 53 & 6288.5762389464 & 96.7063705729 & 20007 & 6209.6424888061\\
      5 & 1000 & 0.9 & 53 & 31127.7188550318 & 96.7043901178 & 588764 & 30729.6443168679\\
      10 & 1000 & 0.9 & 53 & 31127.7188550318 & 96.7043901178 & 10735312 & 30729.6443166712\\
      20 & 1000 & 0.9 & 53 & 31127.7188550318 & 96.7043901178 & 20013 & 30729.6408804572\\
      \hline
    \end{tabular}
    \caption[Selected Runs $p = 0.9$]{Collection of selected runs for both \texttt{L-BFGS-B} and \texttt{L-BFGS-B-NS}. None of them show convergence since this function is not Lipschitz continuous.}
    \label{p09}
  \end{center}
\end{table}
\pagebreak
\pagebreak
\clearpage
